{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c355f5aa",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "The following sections contain the code for training and evaluation of several different models. For each model, we used a combination of following features - \n",
    "\n",
    "- level\n",
    "- difficulty\n",
    "- learning_stage\n",
    "- gender\n",
    "- user_grade\n",
    "- has_teacher_cnt\n",
    "- is_self_coach\n",
    "- has_student_cnt\n",
    "- belongs_to_class_cnt\n",
    "- has_class_cnt\n",
    "- m_level4_proficiency matrix\n",
    "- m_concept_proficiency matrix\n",
    "- v_upid_acc matrix\n",
    "- v_ucid_acc matrix\n",
    "\n",
    "In each model, our output variable was `is_correct` (i.e.), whether the student got the particular problem right / wrong. Each subsection contains the code for creating the training and testing data and we have reported accuracy of training and testing sets of different sizes. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad97483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df56b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "PATH_FEATURE_STORE = '../data/feature_store'\n",
    "PATH_PREPROCESSED_INPUT = '../data/experiment'\n",
    "PATH_MODEL = '../model'\n",
    "\n",
    "# Files\n",
    "FILE_LOG = os.path.join(PATH_FEATURE_STORE ,'df_log_with_upid_acc.parquet.gzip')\n",
    "FILE_USER_PROCESSED = os.path.join(PATH_PREPROCESSED_INPUT ,'Processed_Info_UserData_train.parquet.gzip')\n",
    "FILE_CONTENT_PROCESSED = os.path.join(PATH_PREPROCESSED_INPUT ,'Processed_Info_Content_train.parquet.gzip')\n",
    "\n",
    "# Feature files\n",
    "FILE_M_CONCEPT_PROFICIENCY = os.path.join(PATH_FEATURE_STORE, 'm_concept_proficiency.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fea8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_user = pd.read_parquet(FILE_USER_PROCESSED)\n",
    "df_content = pd.read_parquet(FILE_CONTENT_PROCESSED)\n",
    "df_log = pd.read_parquet(FILE_LOG)\n",
    "\n",
    "# Join tables based on uuid and ucid\n",
    "df1 = pd.merge(df_log, df_user, how='inner', left_on=['uuid', 'user_grade'], right_on=['uuid', 'user_grade']) # NOTE: user_grade is duplicated in both tables\n",
    "df2 = pd.merge(df1, df_content, on='ucid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16c0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8963f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[: 'gender'] = df.loc[: 'gender'].replace({'unspecified': 0, 'male': 1, 'female': 2})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:2: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df.loc[: 'gender'] = df.loc[: 'gender'].replace({'unspecified': 0, 'male': 1, 'female': 2})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2, 2, 2, 2, 2, ..., NaN, 2, 2, 2, 2]\n",
      "Length: 4323938\n",
      "Categories (3, int64): [2, 1, 0]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[: 'gender'] = df.loc[: 'gender'].replace({'unspecified': 0, 'male': 1, 'female': 2})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[: 'difficulty'] = df.loc[: 'difficulty'].replace({'unset': 0, 'easy': 1, 'normal': 2, 'hard': 3})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:3: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df.loc[: 'difficulty'] = df.loc[: 'difficulty'].replace({'unset': 0, 'easy': 1, 'normal': 2, 'hard': 3})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1, 1, 1, 1, 1, ..., 1, 1, 1, 1, 1]\n",
      "Length: 4323938\n",
      "Categories (4, int64): [1, 3, 2, 0]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[: 'difficulty'] = df.loc[: 'difficulty'].replace({'unset': 0, 'easy': 1, 'normal': 2, 'hard': 3})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[: 'learning_stage'] = df.loc[: 'learning_stage'].replace({'elementary': 0, 'junior': 1, 'senior': 2})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:4: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df.loc[: 'learning_stage'] = df.loc[: 'learning_stage'].replace({'elementary': 0, 'junior': 1, 'senior': 2})\n",
      "/var/folders/vr/lb31j9ld2r9c01216djxfysc0000gn/T/ipykernel_73382/2102033638.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0, 0, 0, 0, 0, ..., 1, 0, 0, 0, 0]\n",
      "Length: 4323938\n",
      "Categories (3, int64): [0, 1, 2]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[: 'learning_stage'] = df.loc[: 'learning_stage'].replace({'elementary': 0, 'junior': 1, 'senior': 2})\n"
     ]
    }
   ],
   "source": [
    "# Assign category labels to Gender, Difficulty and Learning Columns.\n",
    "df.loc[: 'gender'] = df.loc[: 'gender'].replace({'unspecified': 0, 'male': 1, 'female': 2})\n",
    "df.loc[: 'difficulty'] = df.loc[: 'difficulty'].replace({'unset': 0, 'easy': 1, 'normal': 2, 'hard': 3})\n",
    "df.loc[: 'learning_stage'] = df.loc[: 'learning_stage'].replace({'elementary': 0, 'junior': 1, 'senior': 2})\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d25479",
   "metadata": {},
   "source": [
    "### Model 1: Benchmark model - Logistic Regression\n",
    "\n",
    "#### Input Features\n",
    "- level\n",
    "- difficulty\n",
    "- learning_stage\n",
    "- gender\n",
    "- user_grade\n",
    "- has_teacher_cnt\n",
    "- is_self_coach\n",
    "- has_student_cnt\n",
    "- belongs_to_class_cnt\n",
    "- has_class_cnt\n",
    "\n",
    "#### Output Feature\n",
    "- is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88f0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only required columns \n",
    "required_columns = ['is_correct', 'total_attempt_cnt', 'user_grade',\n",
    "                    'used_hint_cnt', 'level', 'difficulty', 'learning_stage', \n",
    "                    'gender',  'has_teacher_cnt', 'is_self_coach', \n",
    "                    'has_student_cnt', 'belongs_to_class_cnt', 'has_class_cnt']\n",
    "                    # ['total_sec_taken', 'is_hint_used'] not in index\n",
    "df_logistic = df[required_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d24eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to numpy array\n",
    "input_data = df_logistic.to_numpy()\n",
    "n = input_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fe31cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3414657"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e5ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is =  (2731725, 8)\n",
      "y_train shape is =  (2731725,)\n",
      "X_eval shape is =  (682932, 8)\n",
      "y_eval shape is =  (682932,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 80 - 20% split for training and testing\n",
    "\n",
    "num_samples = int(n * 0.8)\n",
    "samples = np.random.choice(range(n), num_samples, replace=False)\n",
    "mask = np.ones(n, dtype=bool)\n",
    "mask[samples] = False\n",
    "\n",
    "X_train = input_data[samples, 5:]\n",
    "y_train = input_data[samples, 0]\n",
    "# y_train = np.reshape(y_train, (num_samples, 1))\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "X_eval = input_data[mask, 5:]\n",
    "y_eval = input_data[mask, 0]\n",
    "# y_eval = np.reshape(y_eval, (n - num_samples, 1))\n",
    "y_eval = y_eval.astype('int')\n",
    "\n",
    "print('X_train shape is = ', np.shape(X_train))\n",
    "print('y_train shape is = ', np.shape(y_train))\n",
    "print('X_eval shape is = ', np.shape(X_eval))\n",
    "print('y_eval shape is = ', np.shape(y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb18bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "model = LogisticRegression(random_state=0).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdda6253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6946958115888551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval_scaled = MinMaxScaler().fit_transform(X_eval)\n",
    "model.score(X_eval_scaled, y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd9c9b",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "- Accuracy (n = 3M) = 69.3 %\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf56b0b",
   "metadata": {},
   "source": [
    "### Model 2 - Full model\n",
    "\n",
    "\n",
    "- For how the features were engineered, see the section [Feature Engineering](#Feature-Engineering)\n",
    "- Labels (y) [# logs x 1]:\n",
    "    - Correct or not of the new problem (problem-level)\n",
    "- Features (X):\n",
    "    - Demographics [#logs x 4] [From **df_user**]\n",
    "        - grade (#logs x 1)\n",
    "        - gender (#logs x 3)\n",
    "    - Difficulty features  [#logs x 1]:\n",
    "        - upid accuracy [**From v_upid_acc**]\n",
    "        - ~difficulty (only 3 levels, not quite informative)~\n",
    "        - ~learning_stage (only elementary vs. junior, not quite informative)~\n",
    "    - History features [#logs x 3]: \n",
    "        - most recent 'Level' of this ucid [From **df_log**]\n",
    "        - 'problem_number' of this 'ucid' [From **df_log**]\n",
    "        - 'exercise_problem_repeat_session' of this 'upid' [From **df_log**]        \n",
    "    - One-hot encoding matrix [#logs x #level4 id]:  [**m_level4_id**]\n",
    "        - one-hot encoding of the content ID of the new \n",
    "    - Proficiency matrix [#logs x #level4 id]: [**m_proficiency**]\n",
    "        - encodes the student’s performance of each content (i.e.,level)    \n",
    "- Model:\n",
    "    - Decision Tree\n",
    "    - Logistic Regression\n",
    "        - With L2 penalty\n",
    "        - With L1 penalty\n",
    "    - SVM\n",
    "        - With rbf kernal\n",
    "        - With linear kernal\n",
    "- Evaludate Accuracy:\n",
    "    - Hold-out 20% test set\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4215e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load proficiency matrices\n",
    "m_concept_proficiency = np.load(FILE_M_CONCEPT_PROFICIENCY)[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e7e5a",
   "metadata": {},
   "source": [
    "#### Split the data into 80 - 20% split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69106844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is =  (34591, 1334)\n",
      "y_train shape is =  (34591,)\n",
      "X_test shape is =  (8648, 1334)\n",
      "y_test shape is =  (8648,)\n"
     ]
    }
   ],
   "source": [
    "# set to `num_samples` for using full data. set to a small number for quick testing\n",
    "# n_subset = 10000000 will overflow the RAM limit (this step `np.concatenate()`)\n",
    "n_subset = round((df_log.shape[0] / 100))  # 1% of the data for quick testing\n",
    "\n",
    "num_samples = int(df_log.head(n_subset).shape[0])\n",
    "num_train_samples = int(num_samples * 0.8)\n",
    "\n",
    "np.random.seed(760)\n",
    "samples_train = np.random.choice(range(num_samples), num_train_samples, replace=False)\n",
    "\n",
    "# True: training set / False: test set\n",
    "mask_train = np.zeros(num_samples, dtype=bool)\n",
    "mask_train[samples_train] = True\n",
    "\n",
    "X_train = np.concatenate((\n",
    "        # grade\n",
    "        df_log.head(n_subset).loc[mask_train,\"user_grade\"].to_numpy()[:,np.newaxis],\n",
    "        # gender\n",
    "        df_log.head(n_subset).loc[mask_train,[\"female\",\"male\",\"unspecified\"]].to_numpy(),\n",
    "        # Difficulty features \n",
    "        df_log.head(n_subset).loc[mask_train,[\"v_upid_acc\"]].to_numpy(),\n",
    "        # History features\n",
    "        df_log.head(n_subset).loc[mask_train,\"level\"].to_numpy()[:,np.newaxis],    \n",
    "        df_log.head(n_subset).loc[mask_train,\"problem_number\"].to_numpy()[:,np.newaxis],\n",
    "        df_log.head(n_subset).loc[mask_train,\"exercise_problem_repeat_session\"].to_numpy()[:,np.newaxis],    \n",
    "        # # # one-hot matrix\n",
    "        # m_level4_id[:n_subset,:][mask_train,:],\n",
    "        # proficiency matrix\n",
    "        m_concept_proficiency[:n_subset,:][mask_train,:]\n",
    "        # # interaction between one-hot matrix and proficiency matrix\n",
    "        # m_inter_level4_proficiency[:n_subset,:][mask_train,:]\n",
    "    ), axis=1)\n",
    "\n",
    "y_train = df_log.head(n_subset).loc[mask_train,\"is_correct\"].to_numpy(dtype = bool)\n",
    "\n",
    "X_test = np.concatenate((\n",
    "        # grade    \n",
    "        df_log.head(n_subset).loc[~mask_train,\"user_grade\"].to_numpy()[:,np.newaxis],\n",
    "        # gender\n",
    "        df_log.head(n_subset).loc[~mask_train,[\"female\",\"male\",\"unspecified\"]].to_numpy(),\n",
    "        # Difficulty features \n",
    "        df_log.head(n_subset).loc[~mask_train,[\"v_upid_acc\"]].to_numpy(),\n",
    "        # History features\n",
    "        df_log.head(n_subset).loc[~mask_train,\"level\"].to_numpy()[:,np.newaxis],        \n",
    "        df_log.head(n_subset).loc[~mask_train,\"problem_number\"].to_numpy()[:,np.newaxis],\n",
    "        df_log.head(n_subset).loc[~mask_train,\"exercise_problem_repeat_session\"].to_numpy()[:,np.newaxis],    \n",
    "        # # one-hot matrix\n",
    "        # m_level4_id[:n_subset,:][~mask_train,:],\n",
    "        # proficiency matrix\n",
    "        m_concept_proficiency[:n_subset,:][~mask_train,:]\n",
    "        # # interaction between one-hot matrix and proficiency matrix\n",
    "        # m_inter_level4_proficiency[:n_subset,:][~mask_train,:]    \n",
    "    ), axis=1)\n",
    "y_test = df_log.head(n_subset).loc[~mask_train,\"is_correct\"].to_numpy(dtype = bool)\n",
    "\n",
    "print('X_train shape is = ', np.shape(X_train))\n",
    "print('y_train shape is = ', np.shape(y_train))\n",
    "\n",
    "print('X_test shape is = ', np.shape(X_test))\n",
    "print('y_test shape is = ', np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223b045",
   "metadata": {},
   "source": [
    "#### Min-max transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "001960c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite the raw data matrix to reduce RAM usage\n",
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678c396",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe18a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# n_subset = 43239 : train = 0.8899713798386863 ; test = 0.6979648473635522\n"
     ]
    }
   ],
   "source": [
    "dc_full = DecisionTreeClassifier(criterion=\"entropy\", random_state=0).fit(X_train, y_train)\n",
    "print(\"# n_subset = \" + str(n_subset),\": \",end = \"\")\n",
    "print(\"train = \" + str(dc_full.score(X_train, y_train))+\" ; \",end = \"\")\n",
    "print(\"test = \" + str(dc_full.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33272e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH_MODEL}/DecisionTreeClassifier.pkl\", \"wb\") as f:\n",
    "    dump(dc_full, f, protocol=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86347f",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "630d0909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# n_subset = 43239 : train = 0.7621346593044434 ; test = 0.760522664199815\n"
     ]
    }
   ],
   "source": [
    "gb_full = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "print(\"# n_subset = \" + str(n_subset),\": \",end = \"\")\n",
    "print(\"train = \" + str(gb_full.score(X_train, y_train))+\" ; \",end = \"\")\n",
    "print(\"test = \" + str(gb_full.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cc00d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH_MODEL}/GradientBoostingClassifier.pkl\", \"wb\") as f:\n",
    "    dump(gb_full, f, protocol=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78de513",
   "metadata": {},
   "source": [
    "#### Logistic Model (with L2 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367a10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# n_subset = 43239 : train = 0.7591859154115232 ; test = 0.7643385753931545\n"
     ]
    }
   ],
   "source": [
    "logit_full = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "print(\"# n_subset = \" + str(n_subset),\": \",end = \"\")\n",
    "print(\"train = \" + str(logit_full.score(X_train, y_train))+\" ; \",end = \"\")\n",
    "print(\"test = \" + str(logit_full.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27f549d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH_MODEL}/LogisticRegression_L2.pkl\", \"wb\") as f:\n",
    "    dump(logit_full, f, protocol=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa40f5b",
   "metadata": {},
   "source": [
    "#### Logistic Model (with L1 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86aaf9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# n_subset = 43239 : train = 0.7601688300424966 ; test = 0.7629509713228492\n"
     ]
    }
   ],
   "source": [
    "lasso_full = LogisticRegression(penalty='l1', solver='saga', random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "print(\"# n_subset = \" + str(n_subset),\": \",end = \"\")\n",
    "print(\"train = \" + str(lasso_full.score(X_train, y_train))+\" ; \",end = \"\")\n",
    "print(\"test = \" + str(lasso_full.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ec012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH_MODEL}/LogisticRegression_L1.pkl\", \"wb\") as f:\n",
    "    dump(lasso_full, f, protocol=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
